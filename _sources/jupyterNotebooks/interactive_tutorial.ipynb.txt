{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Basic usage tutorial \n",
    "\n",
    "## Installation in Unix\n",
    "\n",
    "  - conda installation. Type in your console the following command:   \n",
    "    ```bash\n",
    "     wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
    "    ```\n",
    "\n",
    "  - Then add miniconda to your path\n",
    "    ```bash\n",
    "     ./miniconda.sh -b -p $HOME/miniconda\n",
    "    ```\n",
    "\n",
    "  - Create new virtual environment\n",
    "    ```bash\n",
    "     conda create -q -n qmflows python=3.5\n",
    "    ```\n",
    "\n",
    "  - Install dependecies\n",
    "    ```bash \n",
    "     conda install --name qmflows -c anaconda hdf5\n",
    "     conda install --name qmflows -c https://conda.anaconda.org/rdkit rdkit\n",
    "    ```\n",
    "\n",
    "  - Start environment\n",
    "    ```bash\n",
    "     source activate qmflows\n",
    "    ```\n",
    "\n",
    "  - install **qmflows** dependencies\n",
    "    ```bash\n",
    "     pip install https://github.com/SCM-NV/qmflows/tarball/master#egg=qmflows https://github.com/SCM-NV/plams/tarball/master#egg=plams --upgrade\n",
    "    ```\n",
    "### You are ready to start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the environment\n",
    "Once *QMflows*  has been installed the user should run the following command to initialize the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "[user@int1 ~]$ source activate qmflows\n",
    "discarding /home/user/anaconda3/bin from PATH\n",
    "prepending /home/user/anaconda3/envs/qmflows/bin to PATH\n",
    "(qmflows)[user@int1 ~]$ python --version\n",
    "Python 3.5.2 :: Anaconda custom (64-bit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To leave the environment the following command is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "(qmflows)[user@int1 ~]$ source deactivate\n",
    "discarding /home/user/anaconda3/envs/qmflows/bin from PATH\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finalize preparations before running QMflows: if you don't want the results  to end up in the current work directory, create a new results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir tutorial_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is QMflows?\n",
    "QMflows is a python library that enables executing complicated workflows of interdependent quantum chemical (QM) calculations in python. It aims at providing a common interface to multiple QM packages, enabling easy and systematic generation of the calculation inputs, as well as facilitating automatic analysis of the results. Furthermore it is build on top of the powerful Noodles framework for executing the calculations in parallel where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics: calling packages\n",
    "Currently **QMFLOWS** offers an interface with the following simulation software:\n",
    "\n",
    "* **SCM (ADF and DTFB)**\n",
    "* **CP2K**\n",
    "* **ORCA**\n",
    "* **GAMESS-US**\n",
    "* **DIRAC**\n",
    "\n",
    " *Please make sure that the packages you want to use in QMflows are installed and active; in most supercomputer the simulation package are available using a command like (consult your system administrator):*\n",
    "\n",
    "```bash\n",
    " load module superAwesomeQuantumPackage/3.1421\n",
    "```\n",
    "\n",
    "*Also some simulation packages required that you configure a `scratch` folder. For instance *Orca* requires a `SCR` folder to be defnied while *ADF*  called it `SCM_TMPDIR`.*\n",
    "\n",
    "\n",
    "With ``qmflows`` you can write a python script that simply calls one of the package objects \n",
    "`adf, dftb, cp2k, orca, gamess or dirac`.\n",
    "As arguments to the call, you need to provide a ``settings`` objects defining the input of a calculation, a molecular geometry, and, optionally, a job name that enables you to find back the \"raw\" data of the calculation later on.\n",
    "\n",
    "Let's see how this works:\n",
    "\n",
    "First we define a molecule, for example by reading one from an xyz file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1bb7c53b45bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMolecule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macetonitrile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"files/acetonitrile.xyz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macetonitrile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plams'"
     ]
    }
   ],
   "source": [
    "from plams import Molecule\n",
    "acetonitrile = Molecule(\"files/acetonitrile.xyz\")\n",
    "print(acetonitrile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can perform geometry optimization on the molecule by a call to the dftb package object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qmflows import dftb, templates, run\n",
    "job = dftb(templates.geometry, acetonitrile, job_name=\"dftb_geometry_optimization\")\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, \"job\" is a so-called \"promised object\". It means it first needs to be \"run\" by the Noodles scheduler to return a normal python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run(job, path=\"tutorial_results\", folder=\"run_one\", cache=\"tutorial_cache.json\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve the calculated properties from the DFTB calculation such as the dipole or the optimized geometry for use in subsequent calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dipole: \", result.dipole)\n",
    "print(result.molecule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and templates\n",
    "In the above example ``templates.geometry`` was actually a predefined Settings object.\n",
    "You can define and manipulate Settings in a completely flexible manner as will be explained in this section. To facilitate combining different packages in one script, QMflows defines a set of commonly used generic keywords, which can be combined with package specific keywords, to provide maximum flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qmflows import Settings\n",
    "s = Settings()\n",
    "s.basis = \"DZP\"\n",
    "s.specific.adf.basis.core = \"large\"\n",
    "s.freeze = [1,2,3]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet illustrates that the ``Settings`` can be specified in two ways, using generic or specific keywords. Generic keywords represent input properties that are present in most simulation packages like a *basis set* while *specific* keywords allow the user to apply specific keywords for a package that are not in a generic dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Expert info: *Settings* are a subclass of python [dictionaries](https://docs.python.org/3.5/tutorial/datastructures.html#dictionaries) to represent herarchical structures, like\n",
    "<img src=\"files/simpleTree.png\"> </font>\n",
    "\n",
    "In QMflows/PLAMS multiple settings objects can be combined using the ``overlay`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_settings = templates.geometry.overlay(s)\n",
    "print(merged_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *overlay* method merged the template containing default settings for geometry optimizations with different packages with the arguments provided by the user \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "Image(filename=\"files/merged.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resulting in:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image(filename=\"files/result_merged.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the generic and specific keywords still exist next to each other and may not be consistent (e.g. different basis sets are defined in generic and specific keywords). Upon calling a package with a Settings object, the generic keywords are first translated into package specific keywords and combined with the relevant user defined specific keywords. In this step, the settings defined in generic keywords take preference. Subsequently, the input file(s) for the given package is/are generated, based on the keywords after **specific.[package]** based on the [PLAMS software](https://www.scm.com/doc/plams/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qmflows import adf\n",
    "print(adf.generic2specific(merged_settings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of adf the above keywords result in the following input file for ADF package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_job = adf(merged_settings, acetonitrile, job_name='adf_acetonitrile')\n",
    "result = run(adf_job, path=\"tutorial_results\", \n",
    "             folder=\"run_two\", cache=\"tutorial_cache.json\")\n",
    "print(open('tutorial_results/run_two/adf_acetonitrile/adf_acetonitrile.in').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining multiple jobs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple jobs can be combined, while calling the run function only once. The script below combines components outlined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plams import Molecule\n",
    "from qmflows import dftb, adf, templates, run, Settings\n",
    "\n",
    "acetonitrile = Molecule(\"files/acetonitrile.xyz\")\n",
    "\n",
    "dftb_opt = dftb(templates.geometry, acetonitrile, job_name=\"dftb_opt\")\n",
    "\n",
    "s = Settings()\n",
    "s.basis = \"DZP\"\n",
    "s.specific.adf.basis.core = \"large\"\n",
    "adf_single = adf(templates.singlepoint.overlay(s), dftb_opt.molecule, job_name=\"adf_single\")\n",
    "\n",
    "adf_result = run(adf_single, path=\"tutorial_results\", folder=\"workflow\", cache=\"tutorial_cache.json\")\n",
    "print(adf_result.molecule)\n",
    "print(adf_result.energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this case the second task adf_single reads the molecule optimized in the first job dftb_opt. Note that dftb_opt as well as dftb_opt.molecule are promised objects. When **run** is applied to the adf_single job, noodles builds a graph of dependencies and makes sure all the calculations required to obtain **adf_result** are performed.\n",
    "\n",
    "All data related to the calculations, i.e. input files generated by QMflows and the resulting output files generated by the QM packages are stored in folders named after the job_names, residing inside a results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tutorial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tutorial_results/workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tutorial_results/workflow/adf_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
